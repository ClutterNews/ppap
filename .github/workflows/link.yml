name: Get links

on:
  schedule:
    - cron: 0/10 * * * *

  push:
    branches:
      - main

jobs:
  prepare:
    name: Prepare
    timeout-minutes: 1
    runs-on: ubuntu-latest
    outputs:
      sites: ${{ steps.sites.outputs.value }}
    steps:
      - name: Checkout crawl
        uses: actions/checkout@v4
        with:
          repository: ClutterNews/nodejs-crawler
          token: ${{ secrets.GH_PAT }}

      - name: Check list website
        id: sites
        run: |
          CONTENT=`cat ./src/conf/websites.json`
          # Remove leading spaces from each line
          CONTENT=$(echo "$CONTENT" | sed 's/^[ \t]*//')
          # the following lines are only required for multi line json
          CONTENT="${CONTENT//'%'/'%25'}"
          CONTENT="${CONTENT//$'\n'/'%0A'}"
          CONTENT="${CONTENT//$'\r'/'%0D'}"
          # end of optional handling for multi line json
          echo "value=$CONTENT" >> $GITHUB_OUTPUT

      - name: Echo value
        run: echo "${{ steps.sites.outputs.value }}"

  get-link:
    name: Get link of ${{ matrix.site_name}}
    runs-on: ubuntu-latest
    needs: [prepare]
    continue-on-error: true
    strategy:
      fail-fast: true
      matrix:
        include: ${{ fromJson(needs.prepare.outputs.sites) }}
    env:
      SITE_URL: ${{ matrix.site_url }}

    steps:
      - name: Checkout crawl
        uses: actions/checkout@v4
        with:
          repository: ClutterNews/nodejs-crawler
          path: crawler
          token: ${{ secrets.GH_PAT }}

      - name: Run get link
        working-directory: crawler
        run: node index.js
